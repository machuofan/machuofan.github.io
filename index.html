<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script type="text/javascript" src="js/hidebib.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Shilong Zhang</title>
 
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Shilong Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <!-- <link rel="icon" type="image/png" href="images/JHU_icon.jpg"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shilong Zhang(张士龙)</name>
              </p>
              Shilong is a first-year(2023-now) Ph.D. student in the Department of Computer Science at The University of Hong Kong (<a href="https://www.cs.hku.hk/">HKU</a>), under the guidance of Prof.<a href="http://luoping.me/">Ping Luo</a>.
                Prior to this, he worked at Shanghai AI Lab, where he was part of the team led by <a href="http://chenkai.site/"> kai Chen</a>. </p>
              <p>  Shilong completed his Bachelor's degree at the University of Science and Technology of China (<a href="https://www.ustc.edu.cn">USTC</a>) in 2019 and was recognized as one of the  <a href="https://www.teach.ustc.edu.cn/?attachment_id=9884">outstanding graduates</a>(73/1824 &asymp;  <b>4%</b>).
               <p> His research interests are primarily focused on computer vision and deep learning, specifically Object Detection and Large Vision-Language Model. He is also a core developer of <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> and <a href="https://github.com/open-mmlab/mmcv">MMCV</a>.</p>
              
              <p style="text-align:center">
                <a href="mailto:2392587229zsl@gmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?hl=zh-CN&user=s1NMu_UAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="">CV</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?user=X3vVZPcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://github.com/jshilong">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:300%;max-width:300%">
              <a href="images/ShilongZhang.jpg"><img style="width:110%;max-width:110%;border-radius:15%" alt="profile photo" src="images/ShilongZhang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <hr>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Recent News</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <ul>
              <li> <b>[2023/7/7]</b> We present a vision and language model named <a href="https://github.com/jshilong/GPT4RoI"> GPT4RoI</a> to do region-level image understanding.     . </li>
                <li> <b>[2023/4/26]</b> We present a vision and language model named  <a href="https://github.com/open-mmlab/Multimodal-GPT"> MultiModal-GPT</a>  . </li>
              <li> <b>[2023/3/20]</b> Two papers was accepted by <b>CVPR 2023.</b> DDQ DETR achieve 52.1 AP with R-50 backbone within 12 epochs. </li>
                <li> <b>[2022/3/15]</b> One paper was accepted by <b>CVPR 2022.</b> </li>
                <li> <b>[2021/11/27]</b> We release <a href="https://github.com/open-mmlab/mmfewshot"> MMFewShot</a>, an open source few shot learning toolbox based on PyTorch. </li>
             <li> <b>[2021/5/8]</b> One paper was accepted by <b>ICML 2021.</b> </li>
              <li> <b>[2020/2/24]</b> One paper was accepted by <b>CVPR 2020.</b></li>
              <li> <b>[2019/6/28]</b> Awarded as outstanding graduates by USTC. </li>

             
            </ul>
          </td>
        </tr>
        </tbody></table>
        <hr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>


          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                 <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/gpt4roi.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="./images/gpt4roi.pdf">[1] GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest </a> &nbsp&nbsp
              <b>Shilong Zhang*</b>, Peize Sun*, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Kai Chen, Ping Luo
              <br>
                <em>(* Equal contribution) </em>,
                <br>

                <font color="black">We present a vision and language model named GPT4RoI to do region-level image understanding. <br>  <a href="https://github.com/jshilong/GPT4RoI"> Code has been  released at this repo !</a> <br> </font>
                <br>
                </p>

            </td>
        </tr> <!--xie2020advprop-->



          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                 <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/gpt.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="">[2] MultiModal-GPT: A Vision and Language Model for Dialogue with Humans </a> &nbsp&nbsp
                <br>
                Tao Gong*, Chengqi Lyu*, <b>Shilong Zhang*</b>,  Yudong Wang*, Miao Zheng*, Qian Zhao*, Kuikun Liu*, Wenwei Zhang*, Ping Luo, Kai Chen
                <br>
                <em>(* random order) </em>,
                <br>

                <font color="black">We present a vision and language model named MultiModal-GPT to conduct multi-round dialogue with humans. <br>  <a href="https://github.com/open-mmlab/Multimodal-GPT"> Code has been  released at this repo !</a> <br> </font>
                <br>
                </p>

            </td>
        </tr> <!--xie2020advprop-->



          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                 <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/ddq.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="">[3] Dense Distinct Query for End-to-End Object Detection </a> &nbsp&nbsp


                <br>
                <b>Shilong Zhang*</b>, Xinjiang Wang*, Jiaqi Wang, Jiangmiao Pang, Chengqi Lyu, Wenwei Zhang, Ping Luo, Kai Chen
                <br>
                <em>CVPR2023(* Equal contribution) </em>,
                <br>
                
                <font color="black">DDQ-DETR achieves 52.1 AP on MS-COCO dataset within 12 epochs using a ResNet-50 backbone, outperforming all existing detectors in the same setting. <br>  <a href=https://github.com/jshilong/DDQ > Code has been  released at this repo !</a> <br> </font>
                <br>
                </p>

            </td>
        </tr> <!--xie2020advprop-->


        <tr bgcolor="#ffffff">
          <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/c_teacher.png' width="250"></div>
          </td>
          <td width="75%" valign="middle">
            <p>
            <a href="https://arxiv.org/abs/2209.01589">[4] Consistent-Teacher: Towards Reducing Inconsistent Pseudo-targets in Semi-supervised Object Detection </a> &nbsp&nbsp

              <br>
              Xinjiang Wang*, Xingyi Yang*, <b>Shilong Zhang</b>, Yijiang Li, Litong Feng, Shijie Fang, Chengqi Lyu, Kai Chen, Wayne Zhang
                
              <br>
              <em>CVPR2023 (* Equal contribution) </em>,
              <br>
              <font color="black">It
                achieves 40.0 mAP with ResNet-50 backbone given only 10% of annotated MS-COCO data, which
                surpasses previous baselines using pseudo labels by around 3 mAP. When trained on fully annotated
                MS-COCO with additional unlabeled data, the performance further increases to 47.2 mAP.</font>
              <br>


          </td>
      </tr> <!--xie2020advprop-->



         <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/grouprcnn.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="https://arxiv.org/abs/2205.05920">[5] Group R-CNN for Point-based Weakly Semi-supervised Object Detection </a> &nbsp&nbsp

                <br>
                  <b>Shilong Zhang*</b>, Zhuoran Yu*, Liyang Liu*, Xinjiang Wang, Aojun Zhou, Kai Chen
                <br>
                <em>CVPR2022 (* Equal contribution) </em>,
                <br>
                <font color="black">We study the problem of weakly semi-supervised object detection with points (WSSOD-P).
                    Group R-CNN significantly outperforms the prior method Point DETR by 3.9 mAP with 5% well-labeled images. <br>  <a href=https://github.com/jshilong/GroupRCNN> Code has been released !</a> <br>.</font>
                <br>


            </td>
        </tr> <!--xie2020advprop-->



         <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/pruning.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="https://arxiv.org/abs/2108.00708">[6] Group Fisher Pruning for Practical Network Compression </a> &nbsp&nbsp


                <br>
                   Liyang Liu*, <b>Shilong Zhang*</b>,Zhanghui Kuang,Jing-Hao Xue ,Aojun Zhou
                <br>
                <em>ICML2021 (* Equal contribution) </em>,
                <br>
                <font color="black">We present a general channel pruning framework for complicated structures ! <br>  <a href=https://github.com/jshilong/FisherPruning.git > Code has been released !</a> <br> </font>
                <br>
                </p>

            </td>
        </tr> <!--xie2020advprop-->


        <tr bgcolor="#ffffff">
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/sepc.png' width="250"></div>
            </td>
            <td width="75%" valign="middle">
              <p>
              <a href="https://arxiv.org/abs/2005.03101">[7] Scale-equalizing Pyramid Convolution for object detection </a> &nbsp&nbsp
       
                  <!-- <a herf="images/sepc.pdf">
                    <papertitle>[1] Scale-equalizing Pyramid Convolution for object detection  </papertitle>
                  </a> -->
                <br>

                Xinjiang Wang*, <b>Shilong Zhang*</b> , Zhuoran Yu, Litong Zhang, Wayne Zhang
                <br>
                <em>CVPR2020 (* Equal contribution)</em>,
                <br>
                <font color="black">We proposed a scale-equalizing pyramid convolution method that relaxes the discrepancy between the feature pyramid and the gaussian pyramid.
                    The module boosts the performance about 3.5 mAP in single-stage object detection with negligible inference time.  <a href=https://github.com/jshilong/SEPC > Code has been released !</a> </font>
                <br>
                </p>

            </td>
        </tr> <!--xie2020advprop-->


        </tbody></table>        


        <hr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td width=30% align="center">
              <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=YhKG6U66qGxhpkw9wNq2inR7zEgWsQgm_B10AAnjACw&cl=ffffff&w=a"></script>
            </td>
            <td style="padding:10px">
              <br>
              <p style="text-align:right;">Stolen from <a href="https://jonbarron.info/">Jon Barron</a></p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-131560165-1', 'auto');
  ga('send', 'pageview');
</script>


<!-- End Google Analytics -->



</body>

</html>
